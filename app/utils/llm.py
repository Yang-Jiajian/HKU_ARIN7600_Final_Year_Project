import os
import uuid
import json
import re
import csv
import base64
from typing import Tuple, Optional, List, TypedDict, Dict, Any

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from openai.types.responses.response_output_message import Content
from openai import OpenAI

# å…¨å±€ chat model å¯¹è±¡
_chat_model: Optional[ChatOpenAI] = None
_initialization_error: Optional[str] = None

# å…¨å±€å¤šæ¨¡æ€å®¢æˆ·ç«¯å¯¹è±¡
_multimodal_client: Optional[OpenAI] = None
_multimodal_initialization_error: Optional[str] = None

class ListResponse(TypedDict):
    scores: List[float]

def _build_chat_model(api_base: str, api_key: str, model: str) -> Tuple[object, str]:
    try:
        llm = ChatOpenAI(
            api_key=api_key,
            model=model,
            base_url=api_base,  # supports OpenAI-compatible providers
            temperature=1.0
        )
        return llm, ""
    except Exception as e:  # initialization error
        return None, str(e)


def initialize_chat_model(app):
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å…¨å±€ chat modelã€‚
    
    Args:
        app: Flask åº”ç”¨å®ä¾‹
    """
    global _chat_model, _initialization_error
    
    api_base = app.config.get("LLM_API_BASE") or os.getenv("LLM_API_BASE")
    api_key = app.config.get("LLM_API_KEY") or os.getenv("LLM_API_KEY")
    model = app.config.get("LLM_MODEL") or os.getenv("LLM_MODEL")
    
    if not api_base or not api_key or not model:
        _initialization_error = "LLM configuration missing: Please set LLM_API_BASE, LLM_API_KEY, and LLM_MODEL"
        _chat_model = None
        return
    
    _chat_model, _initialization_error = _build_chat_model(api_base, api_key, model)


def get_chat_model():
    """è·å–å…¨å±€ chat model å¯¹è±¡ã€‚
    
    Returns:
        Tuple[Optional[ChatOpenAI], Optional[str]]: (chat_model, error_message)
    """
    global _chat_model, _initialization_error
    return _chat_model, _initialization_error


def generate_ielts_topic(conversation_id: str, user_id: str):
    """Use LangChain ChatOpenAI to generate a random IELTS Writing Task 2 topic and concise tips."""
    
    llm, init_error = get_chat_model()
    if llm is None:
        error_msg = init_error or "Chat model not initialized"
        return {"error": "Failed to initialize LangChain ChatOpenAI", "detail": error_msg}, 500

    system_prompt = "You are a helpful assistant that creates IELTS Writing Task."
    user_prompt_question = (
        "Generate ONE realistic IELTS Writing Task 2 essay question. "
        "Vary topic randomly (e.g., education, technology, environment, health, culture, work). "
        "Return only the question text in English, without extra commentary."
    )

    # Ask for concise, actionable tips for the generated question
    system_prompt_tips = (
        "You are an IELTS Writing coach. Provide concise, actionable tips for Planning and Writing Task 2."
    )
    user_prompt_tips = (
        "Given the IELTS Writing Task 2 question above, provide a short guidance including:\n"
        "- A possible thesis (one-sentence position)\n"
        "- 2-3 key arguments with a brief justification each\n"
        "- Suggested structure (Intro, Body 1/2, Conclusion)\n"
        "Keep it concise and practical. Output in English using clear bullet points."
    )

    try:
        # First call: generate the question
        response_q = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=user_prompt_question)])
        question = (getattr(response_q, "content", "") or "").strip()
        if not question:
            return {"error": "Empty response from LLM"}, 502

        # Second call: generate tips for the question (include the question for context)
        response_tips = llm.invoke([
            SystemMessage(content=system_prompt_tips),
            HumanMessage(content=f"Question: {question}\n\n{user_prompt_tips}")
        ])
        tips = (getattr(response_tips, "content", "") or "").strip()

        # save the conversation to the history file
        message_id = str(uuid.uuid4())
        record = [
            {
                "message_id": message_id,
                "role": "bot",
                "content": question,
                "tips": tips
            }
        ]
        save_conversation_to_history(conversation_id=conversation_id, user_id=user_id, record=record)
        return record
    except Exception as e:
        return {
            "error": "Failed to call LLM via LangChain",
            "detail": str(e),
        }, 502


def evaluate_ielts_essay(conversation:list, essay:str, conversation_id: str, user_id: str):
    """Score and review an IELTS Task 2 essay using IELTS official criteria.
    Returns a structured JSON with overall band, breakdown, and actionable advice.
    """
    llm, init_error = get_chat_model()
    if llm is None:
        error_msg = init_error or "Chat model not initialized"
        return {"error": "Failed to initialize LangChain ChatOpenAI", "detail": error_msg}, 500
    topic = conversation[0]["content"]
    system = (
        '''
        You are an IELTS Writing Task 2 examiner. Evaluate essays using the official IELTS Writing Task 2 band descriptors:
Task Response, Coherence and Cohesion, Lexical Resource, and Grammatical Range and Accuracy.

Provide:

A fair overall band score from 0 to 9 (increments of 0.5 allowed)
A detailed numerical breakdown for each criterion
Concise strengths, weaknesses, and prioritized suggestions
If the essay is not written in English, give 0 score.
Return your answer STRICTLY in the following plain-text format:

**Overall Score**: [number] out of 9.0\n\n
**Breakdown**:\n\n
**Task Achievement**: [number]\n\n
**Coherence & cohesion**: [number]\n\n
**Lexical Resource**: [number]\n\n
**Grammar Range & Accuracy**: [number]\n\n

**Strengths**: 
...(list of strengths)

**Weaknesses**: 
...(list of weaknesses)

**Suggestions**:
...(list of suggestions)
Do not include extra commentary or explanatory text â€” only the formatted result shown above.
        '''
    )
    user = (
        f"Prompt: {topic}\n\nEssay:\n{essay}\n\n."
    )

    try:
        response = llm.invoke([SystemMessage(content=system), HumanMessage(content=user)])
        content = (getattr(response, "content", "") or "").strip()
        
        if not content:
            return {"error": "Empty response from LLM"}, 503
        
        match = re.search(
            r"\*\*Breakdown\*\*:?([\s\S]*?)(?:\*\*Strengths\*\*|\*\*Weaknesses\*\*|\*\*Suggestions\*\*|$)",
            content,
            re.IGNORECASE,
        )

        breakdown_text = match.group(1).strip() if match else ""

        # Step 2ï¸âƒ£ â€” Remove the Markdown bold formatting (**bold** â†’ plain)
        cleaned = re.sub(r"\*\*(.*?)\*\*", r"\1", breakdown_text)

        # Step 3ï¸âƒ£ â€” Extract float (or integer) scores after the 4 target categories
        pattern = (
            r"(?:Task Achievement|Coherence\s*&\s*cohesion|Lexical Resource|Grammar Range\s*&\s*Accuracy)"
            r"\s*:\s*([0-9]+(?:\.[0-9]+)?)"
        )

        scores = [float(x) for x in re.findall(pattern, cleaned, flags=re.IGNORECASE)]
        
        print(scores)
        with open(f"./app/data/{user_id}/writing_dashboard.csv", "a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(scores)

        

        # save the conversation to the history file
        record = {
            "message_id": str(uuid.uuid4()),
            "role": "bot",
            "content": content
        }
        save_conversation_to_history(conversation_id=conversation_id, user_id=user_id, record=[conversation[-1],record])
        conversation.append(record)
        print(conversation)
        return conversation
    except Exception as e:
        return {"error": "Failed to evaluate essay", "detail": str(e)}, 502


def continue_ielts_conversation(conversation: list, query: str,conversation_id:str, user_id:str):
    """Continue the IELTS feedback conversation with provided context messages.
    conversation: list of {role: 'system'|'user'|'assistant', content: str}
    """
    llm, init_error = get_chat_model()
    if llm is None:
        error_msg = init_error or "Chat model not initialized"
        return {"error": "Failed to initialize LangChain ChatOpenAI", "detail": error_msg}, 500

    # Ensure there is a guiding system prompt to keep the assistant as an IELTS coach
    default_system = SystemMessage(content=(
        "You are an IELTS Writing Task 2 coach. Answer follow-up questions succinctly, "
        "reference previous feedback when relevant, and provide concrete examples."
    ))

    lc_messages = [default_system]
    for m in conversation or []:
        role = (m or {}).get("role", "").strip()
        content = (m or {}).get("content", "")
        if not content:
            continue
        if role == "system":
            lc_messages.append(SystemMessage(content=content))
        elif role == "bot":
            # LangChain's AIMessage would be ideal, but ChatOpenAI accepts plain strings via invoke as well
            from langchain_core.messages import AIMessage
            lc_messages.append(AIMessage(content=content))
        else:
            lc_messages.append(HumanMessage(content=content))
    lc_messages.append(HumanMessage(content=query))
    try:
        response = llm.invoke(lc_messages)
        content = (getattr(response, "content", "") or "").strip()
        if not content:
            return {"error": "Empty response from LLM"}, 502
        record = {
            "message_id": str(uuid.uuid4()),
            "role": "bot",
            "content": content
        }
    
        save_conversation_to_history(conversation_id=conversation_id, user_id=user_id, record=[conversation[-1],record])
        conversation.append(record)
        return conversation
    except Exception as e:
        return {"error": "Failed to continue conversation", "detail": str(e)}, 502


def save_conversation_to_history(conversation_id: str, user_id: str, record: list) -> None:
    """å°†ç”Ÿæˆçš„æœºå™¨äººå†…å®¹ä¿å­˜/è¿½åŠ åˆ°ç”¨æˆ·å†å²æ–‡ä»¶ã€‚
    
    - è·¯å¾„ï¼šapp/data/{user_id}/history.json
    - è‹¥ä¼šè¯å­˜åœ¨ï¼šå‘ conversation è¿½åŠ ä¸€æ¡ role=bot çš„æ¶ˆæ¯
    - è‹¥ä¼šè¯ä¸å­˜åœ¨ï¼šåˆ›å»ºæ–°ä¼šè¯å¹¶å†™å…¥é¦–æ¡æ¶ˆæ¯
    - è‹¥æ–‡ä»¶ä¸å­˜åœ¨ï¼šåˆ›å»ºæ–°æ–‡ä»¶
    - å‘ç”Ÿå¼‚å¸¸æ—¶é™é»˜å¤±è´¥ï¼ˆæ‰“å°é”™è¯¯ï¼‰ï¼Œä¸æŠ›å‡º
    """

    try:
        app_dir = os.path.dirname(os.path.dirname(__file__))
        
        user_data_dir = os.path.join(app_dir, "data", user_id)
        os.makedirs(user_data_dir, exist_ok=True)
        history_path = os.path.join(user_data_dir, "writing_history.json")
        print(f"history path: {history_path}")
        # ===== è¯»å–å†å²æ–‡ä»¶ =====
        history: list = []
        if os.path.exists(history_path):
            with open(history_path, "r", encoding="utf-8") as rf:
                try:
                    history = json.load(rf) or []
                except json.JSONDecodeError:
                    print(f"[WARN] writing_history.json for user {user_id} is corrupted, resetting file.")
                    history = []
        

        if len(history) == 0:
            print(f"history length = 0")
            history.append({
                "conversation_id": conversation_id,
                "title": f"Practice {conversation_id}",
                "conversation": record
            })
        else :
            conv_is_exist = False
            for conv in history:
                if conv["conversation_id"] == conversation_id:
                    conv["conversation"].extend(record)
                    conv_is_exist = True
            if not conv_is_exist:
                history.append({
                    "conversation_id": len(history) + 1,
                    "title": f"Practice {len(history) + 1}",
                    "conversation": record
                })
        

        # ===== å†™å…¥æ–‡ä»¶ =====
        with open(history_path, "w", encoding="utf-8") as wf:
            json.dump(history, wf, ensure_ascii=False, indent=4)

    except Exception as e:
        print(f"[ERROR] Failed to save conversation history for user {user_id}: {e}")


def initialize_multimodal_client(app):
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å…¨å±€å¤šæ¨¡æ€å®¢æˆ·ç«¯ï¼ˆé˜¿é‡Œäº‘ç™¾ç‚¼ï¼‰ã€‚
    
    Args:
        app: Flask åº”ç”¨å®ä¾‹
    """
    global _multimodal_client, _multimodal_initialization_error
    
    api_key = app.config.get("DASHSCOPE_API_KEY") or os.getenv("DASHSCOPE_API_KEY")
    api_base = app.config.get("DASHSCOPE_API_BASE") or os.getenv("DASHSCOPE_API_BASE", "https://dashscope.aliyuncs.com/compatible-mode/v1")
    
    if not api_key:
        _multimodal_initialization_error = "DASHSCOPE_API_KEY configuration missing"
        _multimodal_client = None
        return
    
    try:
        _multimodal_client = OpenAI(
            api_key=api_key,
            base_url=api_base,
        )
        _multimodal_initialization_error = None
    except Exception as e:
        _multimodal_initialization_error = str(e)
        _multimodal_client = None


def get_multimodal_client():
    """è·å–å…¨å±€å¤šæ¨¡æ€å®¢æˆ·ç«¯å¯¹è±¡ã€‚
    
    Returns:
        Tuple[Optional[OpenAI], Optional[str]]: (multimodal_client, error_message)
    """
    global _multimodal_client, _multimodal_initialization_error
    return _multimodal_client, _multimodal_initialization_error


def process_ielts_speaking_task(
    audio_base64: str,
    task_number: int,
    conversation_id: str,
    user_id: str,
    conversation: Optional[List[Dict[str, Any]]] = None,
    return_audio: bool = True,
    audio_format: str = "wav"
) -> Tuple[Dict[str, Any], int]:
    """å¤„ç†é›…æ€å£è¯­ä»»åŠ¡ï¼ˆTask 1, 2, æˆ– 3ï¼‰ã€‚
    
    Args:
        audio_base64: Base64ç¼–ç çš„éŸ³é¢‘æ•°æ®ï¼ˆä¸åŒ…å«data:;base64,å‰ç¼€ï¼‰
        task_number: ä»»åŠ¡ç¼–å·ï¼ˆ1, 2, æˆ– 3ï¼‰
        conversation_id: ä¼šè¯ID
        user_id: ç”¨æˆ·ID
        conversation: å·²æœ‰çš„å¯¹è¯å†å²
        return_audio: æ˜¯å¦è¿”å›éŸ³é¢‘å“åº”
        audio_format: éŸ³é¢‘æ ¼å¼ï¼ˆwav, mp3, webm ç­‰ï¼‰
    
    Returns:
        Tuple[Dict[str, Any], int]: (å“åº”æ•°æ®, HTTPçŠ¶æ€ç )
    """
    client, init_error = get_multimodal_client()
    if client is None:
        error_msg = init_error or "Multimodal client not initialized"
        return {"error": "Failed to initialize multimodal client", "detail": error_msg}, 500
    
    # æ ¹æ®ä»»åŠ¡ç¼–å·è®¾ç½®ä¸åŒçš„æç¤ºè¯
    task_prompts = {
        1: """You are an official IELTS Speaking Examiner conducting Part 1 of the IELTS Speaking test. 
Part 1 typically lasts 4-5 minutes and involves general questions about familiar topics (e.g., home, family, work, studies, interests).

Your task:
After the candidate's response, provide your evaluation based on the four official IELTS criteria:
- Fluency and Coherence
- Lexical Resource
- Grammatical Range and Accuracy
- Pronunciation
If the audio is not in English, give 0 score.
Your standards ALWAYS MUST be very STRICT.
Return your evaluation in the following format:

**Overall Score**: [number] out of 9.0

**Breakdown**:

**Fluency & Coherence**: [number]

**Lexical Resource**: [number]

**Grammatical Range & Accuracy**: [number]

**Pronunciation**: [number]

**Strengths**: 
...(list of strengths)

**Weaknesses**: 
...(list of weaknesses)

**Suggestions**:
...(list of suggestions)""",
        
        2: """You are an official IELTS Speaking Examiner conducting Part 2 of the IELTS Speaking test. 
Part 2 is the "Long Turn" where the candidate speaks for 1-2 minutes on a given topic after 1 minute of preparation.

Your task:
1. Provide a topic card with a task description
2. Listen to the candidate's 1-2 minute speech
3. Evaluate their performance based on the four official IELTS criteria
4. Provide detailed feedback

Return your evaluation in the following format:

**Overall Score**: [number] out of 9.0

**Breakdown**:

**Fluency & Coherence**: [number]

**Lexical Resource**: [number]

**Grammatical Range & Accuracy**: [number]

**Pronunciation**: [number]

**Strengths**: 
...(list of strengths)

**Weaknesses**: 
...(list of weaknesses)

**Suggestions**:
...(list of suggestions)""",
        
        3: """You are an official IELTS Speaking Examiner conducting Part 3 of the IELTS Speaking test. 
Part 3 is a two-way discussion (4-5 minutes) that explores abstract ideas and issues related to the topic in Part 2.

Your task:
1. Ask more abstract and analytical questions
2. Listen to the candidate's responses
3. Engage in a discussion, asking follow-up questions
4. Evaluate their ability to express and justify opinions, analyze, discuss and speculate about issues

Return your evaluation in the following format:

**Overall Score**: [number] out of 9.0

**Breakdown**:

**Fluency & Coherence**: [number]

**Lexical Resource**: [number]

**Grammatical Range & Accuracy**: [number]

**Pronunciation**: [number]

**Strengths**: 
...(list of strengths)

**Weaknesses**: 
...(list of weaknesses)

**Suggestions**:
...(list of suggestions)"""
    }
    
    system_prompt = task_prompts.get(task_number)
    if not system_prompt:
        return {"error": f"Invalid task number: {task_number}. Must be 1, 2, or 3"}, 400
    
    # å‡†å¤‡éŸ³é¢‘æ•°æ®ï¼ˆä½¿ç”¨ä¸test.pyç›¸åŒçš„æ ¼å¼ï¼‰
    # å¦‚æœå·²ç»åŒ…å«data:å‰ç¼€ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æå–base64éƒ¨åˆ†å¹¶æ·»åŠ å‰ç¼€
    if audio_base64.startswith("data:"):
        # å¦‚æœå·²ç»åŒ…å«å®Œæ•´çš„æ•°æ®URLï¼Œç›´æ¥ä½¿ç”¨
        audio_data_url = audio_base64
    else:
        # å¦‚æœæ˜¯çº¯base64å­—ç¬¦ä¸²ï¼Œæ·»åŠ å‰ç¼€
        audio_data_url = f"data:;base64,{audio_base64}"
    
    # æ„å»ºæ¶ˆæ¯å†…å®¹
    content_items = [
        {
            "type": "input_audio",
            "input_audio": {
                "data": audio_data_url,
                "format": audio_format,  # æ”¯æŒ wav, mp3, webm ç­‰æ ¼å¼
            },
        },
        {
            "type": "text",
            "text": system_prompt
        }
    ]
    
    # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡
    if conversation:
        context_text = "\n\nPrevious conversation:\n"
        for msg in conversation:  # åªä¿ç•™æœ€è¿‘3æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
            role = msg.get("role", "")
            content = msg.get("content", "")
            if role == "user":
                context_text += f"Candidate: {content}\n"
            elif role == "bot":
                context_text += f"Examiner: {content}\n"
        content_items.append({
            "type": "text",
            "text": context_text
        })
    
    try:
        # è°ƒç”¨å¤šæ¨¡æ€API
        completion = client.chat.completions.create(
            model=os.getenv("DASHSCOPE_MODEL", "qwen3-omni-flash"),
            messages=[
                {
                    "role": "user",
                    "content": content_items,
                },
            ],
            modalities=["text", "audio"] if return_audio else ["text"],
            audio={"voice": "Cherry", "format": "wav"} if return_audio else None,
            stream=True,
            stream_options={"include_usage": True},
        )
        
        # å¤„ç†æµå¼å“åº”
        text_response = ""
        audio_string = ""
        transcript = ""
        
        for chunk in completion:
            if chunk.choices:
                if hasattr(chunk.choices[0].delta, "content") and chunk.choices[0].delta.content:
                    text_response += chunk.choices[0].delta.content
                
                if hasattr(chunk.choices[0].delta, "audio") and chunk.choices[0].delta.audio:
                    try:
                        if "data" in chunk.choices[0].delta.audio:
                            audio_string += chunk.choices[0].delta.audio["data"]
                        if "transcript" in chunk.choices[0].delta.audio:
                            transcript += chunk.choices[0].delta.audio.get("transcript", "")
                    except Exception as e:
                        print(f"Error processing audio chunk: {e}")
        
        if not text_response:
            return {"error": "Empty response from multimodal API"}, 502
        
        # è§£æè¯„åˆ†
        scores = extract_speaking_scores(text_response)
        
        # ä¿å­˜è¯„åˆ†åˆ°dashboard
        if scores and len(scores) >= 4:
            save_speaking_scores(user_id, scores)
        
        # å‡†å¤‡å“åº”æ•°æ®
        response_data = {
            "text": text_response,
            "scores": scores,
            "transcript": transcript if transcript else None
        }
        
        # å¦‚æœæœ‰éŸ³é¢‘å“åº”ï¼Œä½¿ç”¨base64ç¼–ç çš„å­—ç¬¦ä¸²
        if return_audio and audio_string:
            response_data["audio"] = audio_string
        
        # ä¿å­˜å¯¹è¯å†å²
        user_message = {
            "message_id": str(uuid.uuid4()),
            "role": "user",
            "content": "ğŸ¤ Your recording",
            "conversation_id": int(conversation_id) if str(conversation_id).isdigit() else conversation_id,
            "part": task_number
        }
        bot_message = {
            "message_id": str(uuid.uuid4()),
            "role": "bot",
            "content": text_response,
            "conversation_id": int(conversation_id) if str(conversation_id).isdigit() else conversation_id,
            "part": task_number
        }

        # å¦‚æœæœ‰éŸ³é¢‘æ•°æ®ï¼Œä½¿ç”¨base64ç¼–ç ä¿å­˜ä¸ºdata URLæ ¼å¼
        if return_audio and audio_string:
            bot_message["audio"] = f"data:audio/wav;base64,{audio_string}"
        
        # å°†ç”¨æˆ·ä¸Šä¼ çš„åŸå§‹éŸ³é¢‘ä¹Ÿä¿å­˜åˆ°å†å²ï¼ˆä½¿ç”¨ data URLï¼Œä¿ç•™æ ¼å¼ï¼‰
        try:
            if audio_base64:
                # è‹¥å‰ç«¯å·²ç»ä¼ æ¥å¸¦ data: å‰ç¼€çš„æ•°æ®ï¼Œæ­¤å¤„ç›´æ¥å¤ç”¨ï¼Œå¦åˆ™è¡¥ä¸Šå‰ç¼€
                if audio_base64.startswith("data:"):
                    user_message["audio"] = audio_base64
                else:
                    # é»˜è®¤ä½¿ç”¨ä¼ å…¥çš„ audio_format
                    fmt = audio_format or "wav"
                    user_message["audio"] = f"data:audio/{fmt};base64,{audio_base64}"
        except Exception as _:
            # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
            pass
        
        save_oral_conversation_to_history(
            conversation_id=conversation_id,
            user_id=user_id,
            record=[user_message, bot_message]
        )
        
        return response_data, 200
        
    except Exception as e:
        return {
            "error": "Failed to process speaking task",
            "detail": str(e)
        }, 502


def extract_speaking_scores(text: str) -> Optional[List[float]]:
    """ä»è¯„ä¼°æ–‡æœ¬ä¸­æå–å£è¯­è¯„åˆ†ã€‚
    
    Args:
        text: åŒ…å«è¯„åˆ†çš„æ–‡æœ¬
    
    Returns:
        List[float]: [Fluency & Coherence, Lexical Resource, Grammatical Range & Accuracy, Pronunciation]
    """
    try:
        # æå–Breakdownéƒ¨åˆ†çš„æ–‡æœ¬
        match = re.search(
            r"\*\*Breakdown\*\*:?([\s\S]*?)(?:\*\*Strengths\*\*|\*\*Weaknesses\*\*|\*\*Suggestions\*\*|$)",
            text,
            re.IGNORECASE,
        )
        
        breakdown_text = match.group(1).strip() if match else ""
        
        # ç§»é™¤Markdownæ ¼å¼
        cleaned = re.sub(r"\*\*(.*?)\*\*", r"\1", breakdown_text)
        
        # æå–å››ä¸ªç»´åº¦çš„åˆ†æ•°
        pattern = (
            r"(?:Fluency\s*&\s*Coherence|Lexical Resource|Grammatical Range\s*&\s*Accuracy|Pronunciation)"
            r"\s*:\s*([0-9]+(?:\.[0-9]+)?)"
        )
        
        scores = [float(x) for x in re.findall(pattern, cleaned, flags=re.IGNORECASE)]
        
        # ç¡®ä¿æœ‰4ä¸ªåˆ†æ•°ï¼ŒæŒ‰é¡ºåºï¼šFluency & Coherence, Lexical Resource, Grammatical Range & Accuracy, Pronunciation
        if len(scores) >= 4:
            return scores[:4]
        elif len(scores) > 0:
            # å¦‚æœåˆ†æ•°ä¸è¶³ï¼Œç”¨0å¡«å……
            while len(scores) < 4:
                scores.append(0.0)
            return scores
        
        return None
    except Exception as e:
        print(f"Error extracting speaking scores: {e}")
        return None


def save_speaking_scores(user_id: str, scores: List[float]) -> None:
    """ä¿å­˜å£è¯­è¯„åˆ†åˆ°dashboard CSVæ–‡ä»¶ã€‚
    
    Args:
        user_id: ç”¨æˆ·ID
        scores: è¯„åˆ†åˆ—è¡¨ [Fluency & Coherence, Lexical Resource, Grammatical Range & Accuracy, Pronunciation]
    """
    try:
        app_dir = os.path.dirname(os.path.dirname(__file__))
        user_data_dir = os.path.join(app_dir, "data", user_id)
        os.makedirs(user_data_dir, exist_ok=True)
        
        dashboard_path = os.path.join(user_data_dir, "oral_dashboard.csv")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
        if not os.path.exists(dashboard_path):
            with open(dashboard_path, "w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "Fluency & Coherence",
                    "Lexical Resource",
                    "Grammatical Range & Accuracy",
                    "Pronunciation"
                ])
        
        # è¿½åŠ è¯„åˆ†æ•°æ®
        with open(dashboard_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(scores)
            
    except Exception as e:
        print(f"[ERROR] Failed to save speaking scores for user {user_id}: {e}")


def generate_ielts_speaking_topic(conversation_id: str, user_id: str, part: int) -> Tuple[Dict[str, Any], int]:
    """ç”Ÿæˆ IELTS å£è¯­é¢˜ç›®ï¼ˆPart 1, 2, æˆ– 3ï¼‰ã€‚
    
    Args:
        conversation_id: ä¼šè¯ID
        user_id: ç”¨æˆ·ID
        part: å£è¯­éƒ¨åˆ†ï¼ˆ1, 2, æˆ– 3ï¼‰
    
    Returns:
        Tuple[Dict[str, Any], int]: (å“åº”æ•°æ®, HTTPçŠ¶æ€ç )
    """
    llm, init_error = get_chat_model()
    if llm is None:
        error_msg = init_error or "Chat model not initialized"
        return {"error": "Failed to initialize LangChain ChatOpenAI", "detail": error_msg}, 500
    
    # æ ¹æ®ä¸åŒçš„ part è®¾ç½®ä¸åŒçš„æç¤ºè¯
    part_prompts = {
        1: {
            "system": "You are an IELTS Speaking Part 1 examiner. Your task is to generate ONE authentic, natural-sounding question â€” but **avoid overused clichÃ©s** (e.g., *Do you enjoy spending time outdoors?*, *Do you like reading?*).  ",
            "user": (
                """
                Draw from a broad range of Part 1 topics: work/study, hometown, accommodation, daily routine, technology, food, weather, hobbies (beyond sports/music), childhood, shopping, transport, pets, etc.  
â†’ Before generating, mentally 'roll a die' to pick a less common subtopic.  
â†’ Keep the question simple, direct, and answerable in 1â€“2 sentences.  
â†’ Output **only the question**, in English, no punctuation extras, no numbering, no quotation marks.
                """
            )
        },
        2: {
            "system": "You are an IELTS Speaking test question generator. Generate realistic Part 2 topic cards.",
            "user": (
                "Generate ONE realistic IELTS Speaking Part 2 topic card. "
                "Part 2 is a 'Long Turn' where candidates speak for 1-2 minutes. "
                "The topic card should include: "
                "1. A main topic (e.g., 'Describe a memorable journey', 'Describe a person you admire') "
                "2. A task description with 2-3 bullet points guiding what to cover. "
                "Format it as a clear topic card with the main topic as a heading and bullet points below. "
                "Return only the topic card content in English, without extra commentary."
            )
        },
        3: {
            "system": "You are an IELTS Speaking test question generator. Generate realistic Part 3 questions.",
            "user": (
                "Generate ONE realistic IELTS Speaking Part 3 question. "
                "Part 3 questions are abstract and analytical, exploring deeper issues related to topics from Part 2. "
                "These questions require candidates to express opinions, analyze, discuss, and speculate. "
                "Examples: 'What are the benefits and drawbacks of...?', 'How do you think... will change in the future?', "
                "'Do you think... is more important than...? Why?' "
                "Return only the question text in English, without extra commentary."
            )
        }
    }
    
    if part not in part_prompts:
        return {"error": f"Invalid part: {part}. Must be 1, 2, or 3"}, 400
    
    prompt = part_prompts[part]
    
    try:
        messages = [
            SystemMessage(content=prompt["system"]),
            HumanMessage(content=prompt["user"])
        ]
        response = llm.invoke(messages)
        content = (getattr(response, "content", "") or "").strip()
        
        if not content:
            return {"error": "Empty response from LLM"}, 502

        # Generate concise answering tips for the given part and question
        tips_system = "You are an IELTS Speaking coach. Provide concise, actionable tips."
        tips_user = ""
        if part == 1:
            tips_user = (
                "Given this Part 1 question, provide a brief guidance on how to answer naturally:\n"
                "- How to structure a 2-3 sentence answer (past/present/examples)\n"
                "- 2-3 helpful phrases or collocations\n"
                "- One common pitfall to avoid\n"
                "Keep it short and practical. Use bullet points. Question: "
                f"{content}"
            )
        elif part == 2:
            tips_user = (
                "Given this Part 2 topic card, provide a brief guidance on how to answer for 1-2 minutes:\n"
                "- A simple outline (opening, 2-3 points, closing)\n"
                "- 3-4 prompts to cover details (who/what/when/where/why/how)\n"
                "- 2-3 helpful linking phrases\n"
                "Keep it short and practical. Use bullet points. Topic:\n"
                f"{content}"
            )
        else:
            tips_user = (
                "Given this Part 3 question, provide a brief guidance on answering analytically:\n"
                "- A structure (position, reasons, examples, mini-conclusion)\n"
                "- 2-3 ideas or angles to consider\n"
                "- 2-3 academic phrases/connectors\n"
                "Keep it short and practical. Use bullet points. Question: "
                f"{content}"
            )

        tips_resp = llm.invoke([SystemMessage(content=tips_system), HumanMessage(content=tips_user)])
        tips = (getattr(tips_resp, "content", "") or "").strip()

        # ä¿å­˜é¢˜ç›®åˆ°å†å²è®°å½•
        message_id = str(uuid.uuid4())
        record = [{
            "message_id": message_id,
            "role": "bot",
            "content": content,
            "tips": tips,
            "conversation_id": int(conversation_id) if conversation_id.isdigit() else conversation_id,
            "part": part
        }]
        
        save_oral_conversation_to_history(
            conversation_id=conversation_id,
            user_id=user_id,
            record=record
        )
        
        return {"question": content, "tips": tips}, 200
        
    except Exception as e:
        return {
            "error": "Failed to generate speaking topic",
            "detail": str(e)
        }, 502


def save_oral_conversation_to_history(conversation_id: str, user_id: str, record: list) -> None:
    """å°†å£è¯­å¯¹è¯å†…å®¹ä¿å­˜/è¿½åŠ åˆ°ç”¨æˆ·å†å²æ–‡ä»¶ã€‚
    
    - è·¯å¾„ï¼šapp/data/{user_id}/history.json
    - è‹¥ä¼šè¯å­˜åœ¨ï¼šå‘ conversation è¿½åŠ æ¶ˆæ¯
    - è‹¥ä¼šè¯ä¸å­˜åœ¨ï¼šåˆ›å»ºæ–°ä¼šè¯å¹¶å†™å…¥é¦–æ¡æ¶ˆæ¯
    - è‹¥æ–‡ä»¶ä¸å­˜åœ¨ï¼šåˆ›å»ºæ–°æ–‡ä»¶
    - å‘ç”Ÿå¼‚å¸¸æ—¶é™é»˜å¤±è´¥ï¼ˆæ‰“å°é”™è¯¯ï¼‰ï¼Œä¸æŠ›å‡º
    """
    try:
        app_dir = os.path.dirname(os.path.dirname(__file__))
        user_data_dir = os.path.join(app_dir, "data", user_id)
        os.makedirs(user_data_dir, exist_ok=True)
        history_path = os.path.join(user_data_dir, "oral_history.json")
        
        # ===== è¯»å–å†å²æ–‡ä»¶ =====
        history: list = []
        if os.path.exists(history_path):
            with open(history_path, "r", encoding="utf-8") as rf:
                try:
                    history = json.load(rf) or []
                except json.JSONDecodeError:
                    print(f"[WARN] history.json for user {user_id} is corrupted, resetting file.")
                    history = []
        
        # è½¬æ¢ conversation_id ä¸ºæ•´æ•°ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        try:
            conv_id_int = int(conversation_id)
        except (ValueError, TypeError):
            conv_id_int = conversation_id
        
        # ===== æŸ¥æ‰¾æˆ–åˆ›å»ºä¼šè¯ =====
        conv_exists = False
        for conv in history:
            # æ”¯æŒæ•´æ•°å’Œå­—ç¬¦ä¸²ç±»å‹çš„ conversation_id æ¯”è¾ƒ
            conv_id = conv.get("conversation_id")
            if conv_id == conv_id_int or str(conv_id) == str(conversation_id):
                conv["conversation"].extend(record)
                # æ›´æ–° selected_partï¼ˆä½¿ç”¨æœ€æ–°æ¶ˆæ¯çš„ partï¼‰
                if record and isinstance(record[0], dict) and "part" in record[0]:
                    conv["selected_part"] = record[0].get("part")
                conv_exists = True
                break
        
        if not conv_exists:
            # åˆ›å»ºæ–°ä¼šè¯
            new_conv = {
                "conversation_id": conv_id_int,
                "title": f"Practice {conv_id_int}",
                "conversation": record,
                "selected_part": record[0].get("part") if record and isinstance(record[0], dict) and "part" in record[0] else None
            }
            history.append(new_conv)
        
        # ===== å†™å…¥æ–‡ä»¶ =====
        with open(history_path, "w", encoding="utf-8") as wf:
            json.dump(history, wf, ensure_ascii=False, indent=4)
            
    except Exception as e:
        print(f"[ERROR] Failed to save oral conversation history for user {user_id}: {e}")